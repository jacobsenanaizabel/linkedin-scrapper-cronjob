# ğŸ¤– LinkedIn Job Scraper - Automated

Scraper automÃ¡tico de vagas no LinkedIn usando GitHub Actions + Apify.

## ğŸ¯ O que faz

- âœ… Executa **automaticamente a cada 3 dias**
- âœ… Procura vagas Senior/Staff Frontend Engineer em Madrid/Remoto
- âœ… Extrai ~200 vagas por execuÃ§Ã£o
- âœ… Inclui detalhes da empresa + info dos recrutadores
- âœ… Gera JSON + CSV para download
- âœ… **Custo: â‚¬0** (dentro do free tier da Apify)

## ğŸ“‹ Setup Inicial

### 1. Fork/Clone este repo

```bash
# Se ainda nÃ£o fizeste:
# 1. Cria conta no GitHub
# 2. Cria novo repo "linkedin-job-scraper"
# 3. Adiciona estes ficheiros
```

### 2. Configurar Apify Token

1. Vai a **Settings** â†’ **Secrets and variables** â†’ **Actions**
2. Clica **New repository secret**
3. Nome: `APIFY_TOKEN`
4. Valor: `YOUR_APIFY_TOKEN_HERE`
5. **Add secret**

### 3. Ativar GitHub Actions

1. Vai ao tab **Actions**
2. Se pedir, clica **I understand my workflows, go ahead and enable them**

## ğŸš€ Como Usar

### ExecuÃ§Ã£o AutomÃ¡tica

O scraper roda **automaticamente**:
- **FrequÃªncia:** A cada 3 dias
- **Hora:** 09:00 UTC (10:00 em Portugal)
- **Sem fazer nada!**

### ExecuÃ§Ã£o Manual

Para executar agora (sem esperar 3 dias):

1. Vai ao tab **Actions**
2. Clica no workflow **"LinkedIn Job Scraper"**
3. Clica **Run workflow** â†’ **Run workflow**
4. Aguarda 3-5 minutos

## ğŸ“¥ Como Obter os Resultados

### OpÃ§Ã£o 1: Via GitHub (Recomendado)

**Para o workflow avanÃ§ado** (`linkedin-scraper-advanced.yml`):

1. Vai ao tab **Actions**
2. Clica na execuÃ§Ã£o mais recente
3. Scroll down atÃ© **Artifacts**
4. Download:
   - `jobs_latest.json` - Dados completos
   - `jobs_latest.csv` - Para Excel/Sheets
   - `summary.json` - EstatÃ­sticas rÃ¡pidas

**Ficheiros expiram em 90 dias**

### OpÃ§Ã£o 2: Via Apify Console

1. Vai a https://console.apify.com/actors/runs
2. Procura pelo run mais recente
3. **Dataset** â†’ **Export** â†’ JSON/CSV/Excel

## âš™ï¸ ConfiguraÃ§Ã£o

### Alterar Queries de Pesquisa

Edita o ficheiro `.github/workflows/linkedin-scraper.yml`:

```python
"searchQueries": [
    "Senior Frontend Engineer Madrid",      # â† Edita aqui
    "Staff Engineer React Spain Remote",    # â† Edita aqui
    "Frontend Lead Next.js Madrid",         # â† Edita aqui
    "Full Stack Engineer Node.js Madrid"    # â† Edita aqui
],
```

### Alterar FrequÃªncia

No mesmo ficheiro, muda o cron:

```yaml
schedule:
  - cron: '0 9 */4 * *'  # A cada 4 dias Ã s 09:00 UTC
```

Exemplos:
- `'0 9 * * 1'` - Todas as segundas Ã s 09:00
- `'0 9 */7 * *'` - A cada 7 dias Ã s 09:00
- `'0 9 1 * *'` - Dia 1 de cada mÃªs Ã s 09:00

**Calculadora de Cron:** https://crontab.guru

### Alterar NÃºmero de Resultados

```python
"maxResults": 50,  # â† 50 jobs por query
```

**AtenÃ§Ã£o:** 
- Mais resultados = mais custo
- Free tier: ~500 jobs/mÃªs
- 4 queries Ã— 50 jobs = 200 total (OK para free tier)

### Alterar Filtros

```python
"filters": {
    "timePosted": "past24Hours",           # past24Hours, pastWeek, pastMonth
    "experienceLevel": ["MID_SENIOR", "DIRECTOR"],  # ENTRY_LEVEL, ASSOCIATE, etc.
    "jobType": ["FULL_TIME"],              # PART_TIME, CONTRACT, TEMPORARY, INTERNSHIP
    "remote": ["REMOTE", "HYBRID"]         # ON_SITE, REMOTE, HYBRID
}
```

## ğŸ“Š Custos

### Free Tier (Atual)

- **Apify:** $5 crÃ©dito/mÃªs
- **GitHub Actions:** 2.000 min/mÃªs
- **ConfiguraÃ§Ã£o atual:** ~500 jobs/mÃªs
- **Custo:** **â‚¬0/mÃªs** âœ…

### Se Ultrapassar Free Tier

Se quiseres mais resultados:

| Jobs/mÃªs | Custo Apify |
|----------|-------------|
| 500 | â‚¬0 (free) |
| 1.000 | â‚¬10-15 |
| 2.000 | â‚¬20-30 |

## ğŸ”” NotificaÃ§Ãµes

### Receber Email quando executar

Adiciona no final do workflow:

```yaml
- name: Send Email
  uses: dawidd6/action-send-mail@v3
  with:
    server_address: smtp.gmail.com
    server_port: 465
    username: ${{ secrets.GMAIL_USER }}
    password: ${{ secrets.GMAIL_PASSWORD }}
    subject: ğŸ¯ LinkedIn Jobs - New Results
    body: Check GitHub Actions for results!
    to: jacobsenanaizabel@gmail.com
```

**Secrets necessÃ¡rios:**
- `GMAIL_USER`: teu Gmail
- `GMAIL_PASSWORD`: App Password do Gmail

## ğŸ“š Estrutura dos Ficheiros

```
linkedin-job-scraper/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ linkedin-scraper.yml           # Workflow bÃ¡sico
â”‚       â””â”€â”€ linkedin-scraper-advanced.yml  # Com download automÃ¡tico
â”œâ”€â”€ README.md                              # Este ficheiro
â””â”€â”€ jobs_latest.json                       # Gerado automaticamente
```

## ğŸ› Troubleshooting

### Workflow nÃ£o executa automaticamente

1. Vai a **Settings** â†’ **Actions** â†’ **General**
2. Scroll down atÃ© **Workflow permissions**
3. Ativa **Read and write permissions**
4. **Save**

### "Resource not accessible by integration"

Mesmo que acima - permissÃµes insuficientes.

### Scraper falha

Verifica:
1. Apify token estÃ¡ correto?
2. Tens crÃ©dito suficiente? (https://console.apify.com/billing)
3. Query syntax estÃ¡ correta?

### Resultados vazios

PossÃ­veis causas:
- Queries muito especÃ­ficas
- Filtros muito restritivos
- PerÃ­odo de tempo muito curto (`past24Hours`)

**SoluÃ§Ã£o:** Alarga os filtros ou muda `timePosted` para `pastWeek`.

## ğŸ“– Links Ãšteis

- **Apify Console:** https://console.apify.com
- **GitHub Actions Logs:** https://github.com/SEU-USERNAME/linkedin-job-scraper/actions
- **Apify Scraper Docs:** https://apify.com/curious_coder/linkedin-jobs-scraper
- **Cron Calculator:** https://crontab.guru

## ğŸ’¡ PrÃ³ximos Passos

Depois de configurar, podes:

1. **Integrar com Google Sheets** (via Google Apps Script)
2. **Filtrar por empresa** (adicionar blacklist de consultorias)
3. **Email automÃ¡tico** com vagas novas
4. **Dashboard** com estatÃ­sticas


**Feito com â¤ï¸ para automatizar a busca de emprego**
